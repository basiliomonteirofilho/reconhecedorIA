<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reconhecedor de Acordes üé∏</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.19.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/meyda/dist/web/meyda.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #101820;
      color: #f5f5f5;
      text-align: center;
      padding: 40px;
    }
    h1 { color: #00e676; }
    input[type="file"] {
      margin: 20px;
      padding: 10px;
      border: 2px dashed #00e676;
      border-radius: 8px;
      background: #1c1c1c;
      color: #fff;
    }
    #result {
      margin-top: 30px;
      font-size: 2em;
      color: #ffea00;
    }
  </style>
</head>
<body>
  <h1>üéß Reconhecedor de Acordes</h1>
  <p>Selecione um arquivo de √°udio (.wav ou .mp3):</p>
  <input type="file" id="audioFile" accept="audio/*" />
  <div id="result">Carregue um arquivo...</div>

  <script>
    let model;
    let chordMap = {};
    let inputShape = { time: 10, mfcc: 13 }; // valor padr√£o, substitu√≠do automaticamente

    const MODEL_URL = "web_model/model.json";
    const CHORD_MAP_URL = "chord_map.json";

    // =====================================================
    // 1Ô∏è‚É£ Carrega modelo e define inputShape autom√°tico
    // =====================================================
    async function loadModel() {
      document.getElementById("result").innerText = "Carregando modelo...";
      model = await tf.loadLayersModel(MODEL_URL);

      // üîç Detecta forma de entrada automaticamente
      const modelData = await fetch(MODEL_URL).then(res => res.json());
      const shape = modelData.modelTopology.model_config.config.layers[0].config.batch_input_shape;
      inputShape = { time: shape[1], mfcc: shape[2] };
      console.log("üîß Detected input shape:", inputShape);

      // Carrega mapeamento de acordes
      const res = await fetch(CHORD_MAP_URL);
      chordMap = await res.json();

      document.getElementById("result").innerText = "‚úÖ Modelo carregado! Pronto.";
    }

    // =====================================================
    // 2Ô∏è‚É£ Extrai MFCCs com ajuste autom√°tico de tamanho
    // =====================================================
    async function extractMFCCs(audioBuffer) {
      const offlineCtx = new OfflineAudioContext(1, audioBuffer.length, audioBuffer.sampleRate);
      const source = offlineCtx.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(offlineCtx.destination);
      source.start(0);

      const rendered = await offlineCtx.startRendering();
      const channelData = rendered.getChannelData(0);

      const frameSize = 1024;
      const hopSize = 512;
      const nMfcc = inputShape.mfcc;
      const fixedFrames = inputShape.time;

      let mfccs = [];

      for (let i = 0; i < channelData.length - frameSize; i += hopSize) {
        const frame = channelData.slice(i, i + frameSize);
        const features = Meyda.extract('mfcc', frame, {
          sampleRate: audioBuffer.sampleRate,
          bufferSize: frameSize,
          numberOfMFCCCoefficients: nMfcc
        });
        if (features && features.mfcc) mfccs.push(features.mfcc);
      }

      // üîπ Ajusta exatamente para o tamanho esperado pelo modelo
      if (mfccs.length > fixedFrames) {
        mfccs = mfccs.slice(0, fixedFrames);
      } else {
        while (mfccs.length < fixedFrames) {
          mfccs.push(new Array(nMfcc).fill(0));
        }
      }

      const tensor = tf.tensor(mfccs, [fixedFrames, nMfcc]).expandDims(0).expandDims(-1);
      console.log("üéõÔ∏è Input tensor shape:", tensor.shape);
      return tensor;
    }

    // =====================================================
    // 3Ô∏è‚É£ Prediz o acorde do arquivo
    // =====================================================
    async function predictChord(file) {
      document.getElementById("result").innerText = "üéµ Analisando √°udio...";
      const audioCtx = new AudioContext();
      const arrayBuffer = await file.arrayBuffer();
      const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      const inputTensor = await extractMFCCs(audioBuffer);

      const prediction = model.predict(inputTensor);
      const predictedIndex = prediction.argMax(-1).dataSync()[0];
      const chordName = chordMap[predictedIndex] || "Desconhecido";

      document.getElementById("result").innerText = `üé∏ Acorde: ${chordName}`;
    }

    // =====================================================
    // 4Ô∏è‚É£ Evento de upload
    // =====================================================
    document.getElementById("audioFile").addEventListener("change", (e) => {
      const file = e.target.files[0];
      if (file && model) predictChord(file);
    });

    loadModel();
  </script>
</body>
</html>
